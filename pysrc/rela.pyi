"""A stub file for rela module."""

from typing import List, Optional, Dict
import torch

TensorDict = Dict[str, torch.Tensor]

class FutureReply:
    def get(self) -> TensorDict: ...
    def is_null(self) -> bool: ...

class Batcher:
    def __init__(self, batch_size: int): ...
    def send(self, t: TensorDict) -> FutureReply: ...
    def get(self) -> TensorDict: ...
    def set(self, t: TensorDict): ...

class BatchRunner:
    def __init__(
        self,
        py_model: torch.jit.ScriptModule,
        device: str,
        max_batch_size: Optional[int],
        methods: Optional[List[str]],
    ): ...
    def add_method(self, method: str, batch_size: int): ...
    def start(self): ...
    def stop(self): ...
    def update_model(self, py_model: torch.jit.ScriptModule): ...
    def set_log_freq(self, log_freq: int): ...
    def block_call(self, method: str, t: TensorDict): ...
    def call(self, method: str, d: TensorDict) -> FutureReply: ...

class ThreadLoop: ...

class Context:
    def __init__(self): ...
    def push_thread_loop(self, env: ThreadLoop) -> int: ...
    def start(self): ...
    def pause(self): ...
    def resume(self): ...
    def join(self): ...
    def terminated(self): ...

# TensorDict utils.
def tensor_dict_stack(vec: TensorDict, stack_dim: int) -> TensorDict: ...
def tensor_dict_eq(d0: TensorDict, d1: TensorDict) -> bool: ...
def tensor_dict_index(batch: TensorDict, i: int) -> TensorDict: ...
def tensor_dict_narrow(
    batch: TensorDict, dim: int, i: int, len: int, squeeze: bool
) -> TensorDict: ...
def tensor_dict_clone(d: TensorDict) -> TensorDict: ...
def tensor_dict_zeros_like(d: TensorDict) -> TensorDict: ...
